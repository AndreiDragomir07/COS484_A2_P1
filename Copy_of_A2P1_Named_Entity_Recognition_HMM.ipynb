{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreiDragomir07/COS484_A2_P1/blob/main/Copy_of_A2P1_Named_Entity_Recognition_HMM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1sXm2wt519o"
      },
      "source": [
        "# Programming Problem 1: HMM for NER\n",
        "Welcome to the programming portion of the assignment! Each assignment throughout the semester will have a written portion and a programming portion. We will be using [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true), so if you have never used it before, take a quick look through this introduction: [Working with Google Colab](https://docs.google.com/document/d/1LlnXoOblXwW3YX-0yG_5seTXJsb3kRdMMRYqs8Qqum4/edit?usp=sharing).\n",
        "\n",
        "### Writing Code\n",
        "Look for the keyword \"TODO\" and fill in your code in the empty space.\n",
        "Feel free to add and delete arguments in function signatures, but be careful that you might need to change them in function calls which are already present in the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEyk2ch1GYi0"
      },
      "source": [
        "### Data preprocessing\n",
        "\n",
        "In this section we will write code to load data and build the dataset for Named Entity Recognition.\n",
        "\n",
        "You may inspect the data first before writing the data preprocessing code by looking at the data file: https://princeton-nlp.github.io/cos484/assignments/a2/eng.train. Hints on processing the data:\n",
        "- You may ignore the lines with \"DOCSTART\"\n",
        "- Examples of NER tags include \"O\", \"ORG\", \"MISC\", and it's always in the same position in each line of the data.\n",
        "- To process numbers more easily, you can replace all digits with 0's (to avoid out-of-vocab words)\n",
        "\n",
        "You should end up with a list of sentences, where each sentence is represented with a list of words and tags.\n",
        "\n",
        "Additional, you will want to support the following functions for later:\n",
        "- Map words and tags to ids (integers)\n",
        "- Handle unknown words in mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lNS57L87IQdT"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "class PreprocessData:\n",
        "    \"\"\"\n",
        "    Preprocess the data: build a list of sentences, where each sentence is a list of (word, tag) tuples.\n",
        "    Also builds word-to-id and tag-to-id mappings.\n",
        "    \"\"\"\n",
        "    def __init__(self, data):\n",
        "        self.sentences = []\n",
        "        current_sentence = []\n",
        "        # set() creates an empty set, which is an unordered collection of unique elements in Python.\n",
        "        word_set = set()\n",
        "        tag_set = set()\n",
        "        for line in data:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                if current_sentence:\n",
        "                    self.sentences.append(current_sentence)\n",
        "                    current_sentence = []\n",
        "                continue\n",
        "            parts = line.split()\n",
        "            if len(parts) < 4:\n",
        "                continue\n",
        "            word, tag = parts[0], parts[3]\n",
        "            if word == \"-DOCSTART-\":\n",
        "                continue\n",
        "            word = re.sub(r'\\d', '0', word)\n",
        "            current_sentence.append((word, tag))\n",
        "            word_set.add(word)\n",
        "            tag_set.add(tag)\n",
        "        if current_sentence:\n",
        "            self.sentences.append(current_sentence)\n",
        "        # Build word-to-id and tag-to-id dictionaries. Reserve 0 for <UNK> for words.\n",
        "        self.word2id = {word: idx+1 for idx, word in enumerate(sorted(word_set))}\n",
        "        self.word2id[\"<UNK>\"] = 0\n",
        "        self.tag2id = {tag: idx+1 for idx, tag in enumerate(sorted(tag_set))}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "train_data_url = \"https://princeton-nlp.github.io/cos484/assignments/a2/eng.train\"\n",
        "response = requests.get(train_data_url)\n",
        "response.raise_for_status() # Raise an exception for HTTP errors\n",
        "train_data_lines = response.text.splitlines()\n",
        "\n",
        "print(f\"Successfully downloaded {len(train_data_lines)} lines of training data.\")\n",
        "print(\"First 5 lines:\")\n",
        "for i in range(min(5, len(train_data_lines))):\n",
        "    print(train_data_lines[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLna66tj5TX2",
        "outputId": "af6ee2ee-eb60-4785-a4bc-8a6343b3dac6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded 219553 lines of training data.\n",
            "First 5 lines:\n",
            "EU NNP I-NP ORG\n",
            "rejects VBZ I-VP O\n",
            "German JJ I-NP MISC\n",
            "call NN I-NP O\n",
            "to TO I-VP O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_train_data = PreprocessData(train_data_lines)\n",
        "\n",
        "print(f\"Number of sentences in training data: {len(processed_train_data.sentences)}\")\n",
        "print(f\"Number of unique words in training data: {len(processed_train_data.word2id)}\")\n",
        "print(f\"Number of unique tags in training data: {len(processed_train_data.tag2id)}\")\n",
        "print(\"First sentence (word, tag) tuples:\")\n",
        "print(processed_train_data.sentences[0])\n",
        "print(\"First 5 word to ID mappings:\")\n",
        "for i, (word, idx) in enumerate(processed_train_data.word2id.items()):\n",
        "    if i >= 5: break\n",
        "    print(f\"  {word}: {idx}\")\n",
        "print(\"First 5 tag to ID mappings:\")\n",
        "for i, (tag, idx) in enumerate(processed_train_data.tag2id.items()):\n",
        "    if i >= 5: break\n",
        "    print(f\"  {tag}: {idx}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNUzywTD5UXY",
        "outputId": "0ceb0dd9-def0-4f0d-f1e8-ed4a9d846b62"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences in training data: 14041\n",
            "Number of unique words in training data: 20101\n",
            "Number of unique tags in training data: 5\n",
            "First sentence (word, tag) tuples:\n",
            "[('EU', 'ORG'), ('rejects', 'O'), ('German', 'MISC'), ('call', 'O'), ('to', 'O'), ('boycott', 'O'), ('British', 'MISC'), ('lamb', 'O'), ('.', 'O')]\n",
            "First 5 word to ID mappings:\n",
            "  !: 1\n",
            "  \": 2\n",
            "  $: 3\n",
            "  %: 4\n",
            "  &: 5\n",
            "First 5 tag to ID mappings:\n",
            "  LOC: 1\n",
            "  MISC: 2\n",
            "  O: 3\n",
            "  ORG: 4\n",
            "  PER: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgikvX-qKTL7"
      },
      "source": [
        "### Hidden Markov Model\n",
        "In this section, we will implement a bigram hidden markov model (HMM) that could perform two types of decoding: greedy decoding and viterbi decoding.\n",
        "\n",
        "Specifically, you should include the following functionalities:\n",
        "- Initialize the HMM given the word and tag mappings.\n",
        "- Train the HMM with a given corpus\n",
        "- Greedy decoding: given a single sentence, output its tags with greedy algorithm\n",
        "- Viterbi decoding: given a single sentence, output its tags using Viterbi\n",
        "\n",
        "You may refer to the lecture notes for more details on the HMM and the decoding algorithms."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class HMM_Train:\n",
        "    \"\"\"\n",
        "    Trains an HMM by counting tag-to-tag transitions and tag-to-word emissions.\n",
        "    Sentence start is treated as a void tag at position 0 (transition from void to first tag).\n",
        "    - transition_counts: (num_tags+1, num_tags+1). Row 0 = counts from void (start of sentence) to each tag.\n",
        "    - emission_counts: (num_tags+1, num_words); emission_counts[tag_idx][word_id] = count.\n",
        "    \"\"\"\n",
        "    def __init__(self, sentences, word2id, tag2id):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences: list of sentences, each sentence is a list of (word, tag) tuples\n",
        "            word2id: dict mapping word -> int id\n",
        "            tag2id: dict mapping tag -> int id. Assumes tag IDs start from 1, and 0 is not occupied.\n",
        "        \"\"\"\n",
        "        self.sentences = sentences\n",
        "        self.word2id = word2id\n",
        "        self.tag2id = tag2id\n",
        "        num_tags = len(tag2id)\n",
        "        num_words = len(word2id)\n",
        "\n",
        "        # Transition counts: (num_tags + 1, num_tags + 1)\n",
        "        # Row 0 = from void (start of sentence)\n",
        "        # Columns 0 = to void (will remain 0), 1..num_tags = to tag id 1..num_tags\n",
        "        self.transition_counts = np.zeros((num_tags + 1, num_tags + 1), dtype=np.float64)\n",
        "\n",
        "        # Emission counts: (num_tags + 1, num_words)\n",
        "        # Row 0 = for void (will remain 0), rows 1..num_tags = for tag id 1..num_tags\n",
        "        self.emission_counts = np.zeros((num_tags + 1, num_words), dtype=np.float64)\n",
        "\n",
        "        for sentence in sentences:\n",
        "            prev_tag_id = 0  # 0 = void (start of sentence)\n",
        "            for word, tag in sentence:\n",
        "                word_id = word2id.get(word, 0) # 0 for <UNK>\n",
        "                tag_id = tag2id[tag] # tag_id is 1-indexed\n",
        "\n",
        "                # Use 1-indexed tag_id directly for column in transition_counts\n",
        "                self.transition_counts[prev_tag_id, tag_id] += 1\n",
        "                # Use 1-indexed tag_id directly for row in emission_counts\n",
        "                self.emission_counts[tag_id, word_id] += 1\n",
        "                prev_tag_id = tag_id\n",
        "\n",
        "    def counts_to_probabilities(self, counts_matrix, k=0.0):\n",
        "        \"\"\"\n",
        "        Converts a count matrix into a probability matrix using add-k smoothing.\n",
        "\n",
        "        Args:\n",
        "            counts_matrix (np.ndarray): The matrix of counts.\n",
        "            k (float): The smoothing parameter (add-k smoothing). Default is 0.0 (no smoothing).\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: The probability matrix.\n",
        "        \"\"\"\n",
        "        if k == 0.0:\n",
        "            # Avoid division by zero for rows that sum to 0 if no smoothing\n",
        "            row_sums = np.sum(counts_matrix, axis=1, keepdims=True)\n",
        "            # Replace 0 sums with 1 to prevent division by zero, resulting in 0 probabilities for that row\n",
        "            row_sums[row_sums == 0] = 1\n",
        "            probabilities = counts_matrix / row_sums\n",
        "        else:\n",
        "            num_columns = counts_matrix.shape[1]\n",
        "            smoothed_counts = counts_matrix + k\n",
        "            denominator = np.sum(counts_matrix, axis=1, keepdims=True) + k * num_columns\n",
        "            probabilities = smoothed_counts / denominator\n",
        "        return probabilities\n"
      ],
      "metadata": {
        "id": "1T2A4VWNY-WC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aee37d74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e817e343-72dc-4110-cbaa-7a46f2da9a5c"
      },
      "source": [
        "hmm_trainer = HMM_Train(\n",
        "    processed_train_data.sentences,\n",
        "    processed_train_data.word2id,\n",
        "    processed_train_data.tag2id\n",
        ")\n",
        "\n",
        "# Calculate transition probabilities (with smoothing)\n",
        "transition_probabilities = hmm_trainer.counts_to_probabilities(\n",
        "hmm_trainer.transition_counts, k=0.1\n",
        ")\n",
        "\n",
        "# Explicitly set the 'to void' probabilities (column 0) to zero, then re-normalize.\n",
        "# This assumes that the 'void' state (tag_id = 0) is never a destination.\n",
        "transition_probabilities[:, 0] = 0.0 # Set all probabilities of transitioning TO void to 0\n",
        "\n",
        "# Re-normalize rows to ensure probabilities sum to 1 after zeroing.\n",
        "# This is crucial for valid probabilities for subsequent calculations.\n",
        "row_sums_after_zeroing = np.sum(transition_probabilities, axis=1, keepdims=True)\n",
        "# Avoid division by zero for rows that might still sum to 0 after zeroing\n",
        "row_sums_after_zeroing[row_sums_after_zeroing == 0] = 1\n",
        "transition_probabilities = transition_probabilities / row_sums_after_zeroing\n",
        "\n",
        "# Calculate emission probabilities (add-10 smoothing)\n",
        "emission_probabilities = hmm_trainer.counts_to_probabilities(\n",
        "hmm_trainer.emission_counts, k=1.0\n",
        ")\n",
        "\n",
        "# Modify the following print statement to print out the transition count matrix:\n",
        "with np.printoptions(suppress=True):\n",
        "    print(\"The transition count matrix is the following: \\n\", hmm_trainer.transition_counts)\n",
        "\n",
        "print(\"Shape of transition probabilities matrix:\", transition_probabilities.shape)\n",
        "print(\"Shape of emission probabilities matrix:\", emission_probabilities.shape)\n",
        "\n",
        "print(\"\\nFull transition probabilities matrix:\")\n",
        "with np.printoptions(suppress=True, threshold=np.inf):\n",
        "    print(transition_probabilities)\n",
        "\n",
        "print(\"\\nFirst 5 rows and 5 columns of emission probabilities:\")\n",
        "print(emission_probabilities[:5, :5])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The transition count matrix is the following: \n",
            " [[     0.   1581.    502.   8154.   2455.   1349.]\n",
            " [     0.   1168.     30.   6927.     11.      1.]\n",
            " [     0.     10.   1190.   3152.     39.     61.]\n",
            " [     0.   5533.   2861. 138886.   3792.   5183.]\n",
            " [     0.      2.      9.   6105.   3728.      6.]\n",
            " [     0.      3.      1.   6354.      0.   4528.]]\n",
            "Shape of transition probabilities matrix: (6, 6)\n",
            "Shape of emission probabilities matrix: (6, 20101)\n",
            "\n",
            "Full transition probabilities matrix:\n",
            "[[0.         0.11260193 0.03575829 0.58071431 0.17484599 0.09607948]\n",
            " [0.         0.14354531 0.00369892 0.85125653 0.00136406 0.00013518]\n",
            " [0.         0.00226839 0.26728804 0.70793936 0.00878158 0.01372263]\n",
            " [0.         0.03541059 0.0183104  0.88883975 0.02426859 0.03317067]\n",
            " [0.         0.00021319 0.00092381 0.61977565 0.3784681  0.00061926]\n",
            " [0.         0.00028476 0.00010104 0.58366785 0.00000919 0.41593717]]\n",
            "\n",
            "First 5 rows and 5 columns of emission probabilities:\n",
            "[[4.97487687e-05 4.97487687e-05 4.97487687e-05 4.97487687e-05\n",
            "  4.97487687e-05]\n",
            " [3.52137474e-05 3.52137474e-05 3.52137474e-05 3.52137474e-05\n",
            "  3.52137474e-05]\n",
            " [4.04956670e-05 8.09913339e-05 4.04956670e-05 4.04956670e-05\n",
            "  4.04956670e-05]\n",
            " [5.27206491e-06 1.05441298e-05 1.14878294e-02 1.91375956e-03\n",
            "  1.26529558e-04]\n",
            " [3.31939189e-05 3.31939189e-05 3.31939189e-05 3.31939189e-05\n",
            "  3.31939189e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4b16ce9"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "\n",
        "class HMM:\n",
        "    def __init__(self, word2id, tag2id, transition_probabilities, emission_probabilities):\n",
        "        self.word2id = word2id\n",
        "        self.tag2id = tag2id\n",
        "        self.id2tag = {v: k for k, v in tag2id.items()}\n",
        "        self.transition_probabilities = transition_probabilities\n",
        "        self.emission_probabilities = emission_probabilities\n",
        "        self.num_tags = len(tag2id)\n",
        "\n",
        "    def greedy_decode(self, sentence):\n",
        "        predicted_tags_ids = []\n",
        "        prev_tag_id = 0  # 0 represents the 'void' start state\n",
        "\n",
        "        for word in sentence:\n",
        "            word_id = self.word2id.get(word, 0) # 0 for <UNK>\n",
        "\n",
        "            best_score = -np.inf\n",
        "            best_tag_id = -1\n",
        "\n",
        "            for current_tag_idx in range(1, self.num_tags + 1): # Iterate through 1-indexed tag IDs\n",
        "\n",
        "                # prev_tag_id (0 for void, or 1-indexed tag ID) as row index\n",
        "                # current_tag_idx (1-indexed tag ID) as column index\n",
        "                trans_prob = self.transition_probabilities[prev_tag_id, current_tag_idx]\n",
        "\n",
        "                # current_tag_idx (1-indexed tag ID) as row index\n",
        "                emit_prob = self.emission_probabilities[current_tag_idx, word_id]\n",
        "\n",
        "                score = np.log(trans_prob) + np.log(emit_prob)\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_tag_id = current_tag_idx # current_tag_idx is already 1-indexed\n",
        "\n",
        "            predicted_tags_ids.append(best_tag_id)\n",
        "            prev_tag_id = best_tag_id # Update previous tag for next iteration\n",
        "\n",
        "        return [self.id2tag[tag_id] for tag_id in predicted_tags_ids]\n",
        "\n",
        "    def viterbi_decode(self, sentence):\n",
        "        sentence_len = len(sentence)\n",
        "\n",
        "        # Viterbi matrix: V[tag_id][word_idx] stores the max log probability\n",
        "        # Backpointer matrix: B[tag_id][word_idx] stores the previous tag_id\n",
        "        # Using num_tags + 1 for rows to directly map 1-indexed tag_ids.\n",
        "        V = np.full((self.num_tags + 1, sentence_len), -np.inf)\n",
        "        B = np.zeros((self.num_tags + 1, sentence_len), dtype=int)\n",
        "\n",
        "        # --- Initialization (t=0) ---\n",
        "        first_word_id = self.word2id.get(sentence[0], 0)\n",
        "        for current_tag_idx in range(1, self.num_tags + 1):\n",
        "            # From void (state 0) to current tag\n",
        "            trans_prob = self.transition_probabilities[0, current_tag_idx]\n",
        "            emit_prob = self.emission_probabilities[current_tag_idx, first_word_id]\n",
        "            V[current_tag_idx, 0] = np.log(trans_prob) + np.log(emit_prob)\n",
        "            B[current_tag_idx, 0] = 0 # No previous tag for the first word (from void)\n",
        "\n",
        "        # --- Recursion (t=1 to sentence_len - 1) ---\n",
        "        for t in range(1, sentence_len):\n",
        "            word_id = self.word2id.get(sentence[t], 0)\n",
        "            for current_tag_idx in range(1, self.num_tags + 1):\n",
        "                best_prev_score = -np.inf\n",
        "                best_prev_tag_id = -1\n",
        "                for prev_tag_idx in range(1, self.num_tags + 1):\n",
        "                    score = V[prev_tag_idx, t-1] \\\n",
        "                            + np.log(self.transition_probabilities[prev_tag_idx, current_tag_idx]) \\\n",
        "                            + np.log(self.emission_probabilities[current_tag_idx, word_id])\n",
        "\n",
        "                    if score > best_prev_score:\n",
        "                        best_prev_score = score\n",
        "                        best_prev_tag_id = prev_tag_idx\n",
        "                V[current_tag_idx, t] = best_prev_score\n",
        "                B[current_tag_idx, t] = best_prev_tag_id\n",
        "\n",
        "        # --- Termination ---\n",
        "        # Find the path with the highest probability at the last word\n",
        "        last_word_col = sentence_len - 1\n",
        "        best_last_tag_id = np.argmax(V[1:, last_word_col]) + 1 # +1 because V[0,:] is unused for tags\n",
        "        # max_log_prob = V[best_last_tag_id, last_word_col] # Not explicitly needed for path reconstruction\n",
        "\n",
        "        # --- Backtracking ---\n",
        "        predicted_tags_ids = [0] * sentence_len\n",
        "        predicted_tags_ids[last_word_col] = best_last_tag_id\n",
        "\n",
        "        for t in range(sentence_len - 1, 0, -1):\n",
        "            predicted_tags_ids[t-1] = B[predicted_tags_ids[t], t]\n",
        "\n",
        "        # Convert tag IDs to actual tag names\n",
        "        return [self.id2tag[tag_id] for tag_id in predicted_tags_ids]\n",
        "\n",
        "    def evaluate_accuracy(self, test_sentences, decoding_method='viterbi'):\n",
        "        if decoding_method not in ['greedy', 'viterbi']:\n",
        "            raise ValueError(\"decoding_method must be 'greedy' or 'viterbi'\")\n",
        "\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for sentence_data in test_sentences:\n",
        "            words = [item[0] for item in sentence_data]\n",
        "            true_tags = [item[1] for item in sentence_data]\n",
        "\n",
        "            if decoding_method == 'greedy':\n",
        "                predicted_tags = self.greedy_decode(words)\n",
        "            else:\n",
        "                predicted_tags = self.viterbi_decode(words)\n",
        "\n",
        "            for i in range(len(true_tags)):\n",
        "                total_predictions += 1\n",
        "                if predicted_tags[i] == true_tags[i]:\n",
        "                    correct_predictions += 1\n",
        "\n",
        "        accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
        "        return accuracy\n",
        "\n",
        "    def compute_confusion_matrix(self, test_sentences, decoding_method='viterbi'):\n",
        "        if decoding_method not in ['greedy', 'viterbi']:\n",
        "            raise ValueError(\"decoding_method must be 'greedy' or 'viterbi'\")\n",
        "\n",
        "        all_true_tags = []\n",
        "        all_predicted_tags = []\n",
        "\n",
        "        for sentence_data in test_sentences:\n",
        "            words = [item[0] for item in sentence_data]\n",
        "            true_tags = [item[1] for item in sentence_data]\n",
        "\n",
        "            if decoding_method == 'greedy':\n",
        "                predicted_tags = self.greedy_decode(words)\n",
        "            else:\n",
        "                predicted_tags = self.viterbi_decode(words)\n",
        "\n",
        "            all_true_tags.extend(true_tags)\n",
        "            all_predicted_tags.extend(predicted_tags)\n",
        "\n",
        "        # Get all unique tags from tag2id, sorted by their ID for consistent order\n",
        "        labels = sorted(self.tag2id.keys(), key=lambda x: self.tag2id[x])\n",
        "\n",
        "        # Compute confusion matrix\n",
        "        cm = confusion_matrix(all_true_tags, all_predicted_tags, labels=labels)\n",
        "        return cm, labels\n",
        "\n",
        "    def compute_f1_score(self, test_sentences, decoding_method='viterbi', average='weighted'):\n",
        "        if decoding_method not in ['greedy', 'viterbi']:\n",
        "            raise ValueError(\"decoding_method must be 'greedy' or 'viterbi'\")\n",
        "\n",
        "        all_true_tags = []\n",
        "        all_predicted_tags = []\n",
        "\n",
        "        for sentence_data in test_sentences:\n",
        "            words = [item[0] for item in sentence_data]\n",
        "            true_tags = [item[1] for item in sentence_data]\n",
        "\n",
        "            if decoding_method == 'greedy':\n",
        "                predicted_tags = self.greedy_decode(words)\n",
        "            else:\n",
        "                predicted_tags = self.viterbi_decode(words)\n",
        "\n",
        "            all_true_tags.extend(true_tags)\n",
        "            all_predicted_tags.extend(predicted_tags)\n",
        "\n",
        "        labels = sorted(self.tag2id.keys(), key=lambda x: self.tag2id[x])\n",
        "\n",
        "        # Compute F1 score\n",
        "        f1 = f1_score(all_true_tags, all_predicted_tags, labels=labels, average=average)\n",
        "        return f1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the HMM model with the calculated probabilities and mappings\n",
        "hmm_model = HMM(\n",
        "    processed_train_data.word2id,\n",
        "    processed_train_data.tag2id,\n",
        "    transition_probabilities,\n",
        "    emission_probabilities\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\n--- Evaluating on Training Data ---\")\n",
        "\n",
        "# Evaluate with greedy decoding on full training set\n",
        "greedy_train_accuracy = hmm_model.evaluate_accuracy(processed_train_data.sentences, decoding_method='greedy')\n",
        "print(f\"Greedy decoding accuracy on training data: {greedy_train_accuracy:.4f}\")\n",
        "\n",
        "# Evaluate with Viterbi decoding on full training set\n",
        "viterbi_train_accuracy = hmm_model.evaluate_accuracy(processed_train_data.sentences, decoding_method='viterbi')\n",
        "print(f\"Viterbi decoding accuracy on training data: {viterbi_train_accuracy:.4f}\")\n",
        "\n",
        "# Compute Confusion Matrix for greedy decoding on training data\n",
        "cm_greedy, cm_labels = hmm_model.compute_confusion_matrix(processed_train_data.sentences, decoding_method='greedy')\n",
        "print(f\"\\nConfusion Matrix (Greedy, training data):\\n{cm_greedy}\")\n",
        "print(f\"Confusion Matrix Labels: {cm_labels}\")\n",
        "\n",
        "# Compute F1 Score for greedy decoding on training data\n",
        "f1_greedy = hmm_model.compute_f1_score(processed_train_data.sentences, decoding_method='greedy')\n",
        "print(f\"F1 Score (Greedy, training data): {f1_greedy:.4f}\")\n",
        "\n",
        "# Compute Confusion Matrix for Viterbi decoding on training data\n",
        "cm_viterbi, _ = hmm_model.compute_confusion_matrix(processed_train_data.sentences, decoding_method='viterbi')\n",
        "print(f\"\\nConfusion Matrix (Viterbi, training data):\\n{cm_viterbi}\")\n",
        "\n",
        "# Compute F1 Score for Viterbi decoding on training data\n",
        "f1_viterbi = hmm_model.compute_f1_score(processed_train_data.sentences, decoding_method='viterbi')\n",
        "print(f\"F1 Score (Viterbi, training data): {f1_viterbi:.4f}\")"
      ],
      "metadata": {
        "id": "-dz3yDKQswQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6P0Qs5JM0x3"
      },
      "source": [
        "### Train and evaluate HMMs.\n",
        "\n",
        "In this section, you will implement the logic for training and evaluating the HMMs:\n",
        "- Train the model by calling the functions/classes you implemented above,\n",
        "- Evaluate the trained model on the training and evaluation set by calculating the accuracy of the predicted tags.\n",
        "- Compute the confusion matrix and F1 score of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFcYYThhPRbh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vRsc-YrRAb2"
      },
      "source": [
        "### Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McZ9KpeQRlA9"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and load the data from the following links\n",
        "\n",
        "https://princeton-nlp.github.io/cos484/assignments/a2/eng.train\n",
        "\n",
        "https://princeton-nlp.github.io/cos484/assignments/a2/eng.val\n",
        "\n",
        "Then load the data using what you implemented"
      ],
      "metadata": {
        "id": "mbeC7vllVJdw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjVwUkR9Rq53"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzNnUiBZS4ME"
      },
      "source": [
        "#### Experiment with an HMM with greedy decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0t7W9JMTfLl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMfHIDQNKQu4"
      },
      "source": [
        "**(a) Which pair of tags does the model have most difficulty separating according to the confusion matrix of the validation set?**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP4iMShYX3Xp"
      },
      "source": [
        "#### Experiment with an HMM with viterbi decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zBEh-TpX8KC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJjLjPCvK6Jr"
      },
      "source": [
        "**(b) What major differences do you observe compared to the matrix in (a)**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Prompts\n",
        "\n",
        "If you used an AI tool to complete any part of this assignment, please paste all prompts you used to produce your final code/responses in the box below and answer the following reflection question."
      ],
      "metadata": {
        "id": "l_g9Yo6JU-9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompts Used:\n",
        "*   \n",
        "*   \n",
        "\n"
      ],
      "metadata": {
        "id": "smbo1v_FVCPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflection: What parts of the AI generated output required modification or improvement? Describe the feedback you gave the tool to produce your final output or any changes you had to make on your own.**\n",
        "\n",
        "TODO: ANSWER THE QUESTION HERE (DOUBLE-CLICK TO EDIT)"
      ],
      "metadata": {
        "id": "R31wWAgxVDMd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "838316a0"
      },
      "source": [
        "# Task\n",
        "Process and evaluate the validation data from \"https://princeton-nlp.github.io/cos484/assignments/a2/eng.val\" using the `PreprocessData` class and the existing HMM model to calculate and print the accuracy, confusion matrix, and F1 score for both greedy and Viterbi decoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d7f5711"
      },
      "source": [
        "## Fetch Validation Data\n",
        "\n",
        "### Subtask:\n",
        "Download the content of the 'eng.val' file from 'https://princeton-nlp.github.io/cos484/assignments/a2/eng.val'. This will involve using the `requests` library to fetch the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "696938ae"
      },
      "source": [
        "**Reasoning**:\n",
        "The user wants to download the validation data. I need to use the `requests` library to fetch the data from the specified URL, handle potential errors, and then process the text into lines, finally printing a confirmation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9cec1c1",
        "outputId": "70196b76-bb98-4ac8-98d1-e0081f59e3a4"
      },
      "source": [
        "import requests\n",
        "\n",
        "val_data_url = \"https://princeton-nlp.github.io/cos484/assignments/a2/eng.val\"\n",
        "response = requests.get(val_data_url)\n",
        "response.raise_for_status() # Raise an exception for HTTP errors\n",
        "val_data_lines = response.text.splitlines()\n",
        "\n",
        "print(f\"Successfully downloaded {len(val_data_lines)} lines of validation data.\")\n",
        "print(\"First 5 lines:\")\n",
        "for i in range(min(5, len(val_data_lines))):\n",
        "    print(val_data_lines[i])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully downloaded 53015 lines of validation data.\n",
            "First 5 lines:\n",
            "CRICKET NNP I-NP O\n",
            "- : O O\n",
            "LEICESTERSHIRE NNP I-NP ORG\n",
            "TAKE NNP I-NP O\n",
            "OVER IN I-PP O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec2e5f39"
      },
      "source": [
        "**Reasoning**:\n",
        "The validation data has been downloaded. Now, I need to preprocess it using the `PreprocessData` class, similar to how the training data was handled. This will convert the raw text lines into a structured format (list of sentences with word-tag tuples) that can be used by the HMM model for evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6973a0a3",
        "outputId": "4e75ef4a-4845-47d9-b2e8-9cf2b208f45a"
      },
      "source": [
        "processed_val_data = PreprocessData(val_data_lines)\n",
        "\n",
        "print(f\"Number of sentences in validation data: {len(processed_val_data.sentences)}\")\n",
        "print(f\"Number of unique words in validation data: {len(processed_val_data.word2id)}\")\n",
        "print(f\"Number of unique tags in validation data: {len(processed_val_data.tag2id)}\")\n",
        "print(\"First sentence (word, tag) tuples from validation data:\")\n",
        "print(processed_val_data.sentences[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences in validation data: 3490\n",
            "Number of unique words in validation data: 8697\n",
            "Number of unique tags in validation data: 5\n",
            "First sentence (word, tag) tuples from validation data:\n",
            "[('CRICKET', 'O'), ('-', 'O'), ('LEICESTERSHIRE', 'ORG'), ('TAKE', 'O'), ('OVER', 'O'), ('AT', 'O'), ('TOP', 'O'), ('AFTER', 'O'), ('INNINGS', 'O'), ('VICTORY', 'O'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b48c864b"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the validation data is preprocessed, I will evaluate the pre-trained HMM model on this validation set using both greedy and Viterbi decoding. I need to calculate and print the accuracy, confusion matrix, and F1 score for each decoding method, similar to how it was done for the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "558c0032",
        "outputId": "0d50f78c-0637-4f35-f040-1f47ac1377d7"
      },
      "source": [
        "print(\"\\n--- Evaluating on Validation Data ---\")\n",
        "\n",
        "# Evaluate with greedy decoding on validation set\n",
        "greedy_val_accuracy = hmm_model.evaluate_accuracy(processed_val_data.sentences, decoding_method='greedy')\n",
        "print(f\"Greedy decoding accuracy on validation data: {greedy_val_accuracy:.4f}\")\n",
        "\n",
        "# Compute Confusion Matrix for greedy decoding on validation data\n",
        "cm_greedy_val, cm_labels_val = hmm_model.compute_confusion_matrix(processed_val_data.sentences, decoding_method='greedy')\n",
        "print(f\"\\nConfusion Matrix (Greedy, validation data):\\n{cm_greedy_val}\")\n",
        "print(f\"Confusion Matrix Labels: {cm_labels_val}\")\n",
        "\n",
        "# Compute F1 Score for greedy decoding on validation data\n",
        "f1_greedy_val = hmm_model.compute_f1_score(processed_val_data.sentences, decoding_method='greedy')\n",
        "print(f\"F1 Score (Greedy, validation data): {f1_greedy_val:.4f}\")\n",
        "\n",
        "# Evaluate with Viterbi decoding on validation set\n",
        "viterbi_val_accuracy = hmm_model.evaluate_accuracy(processed_val_data.sentences, decoding_method='viterbi')\n",
        "print(f\"\\nViterbi decoding accuracy on validation data: {viterbi_val_accuracy:.4f}\")\n",
        "\n",
        "# Compute Confusion Matrix for Viterbi decoding on validation data\n",
        "cm_viterbi_val, _ = hmm_model.compute_confusion_matrix(processed_val_data.sentences, decoding_method='viterbi')\n",
        "print(f\"\\nConfusion Matrix (Viterbi, validation data):\\n{cm_viterbi_val}\")\n",
        "\n",
        "# Compute F1 Score for Viterbi decoding on validation data\n",
        "f1_viterbi_val = hmm_model.compute_f1_score(processed_val_data.sentences, decoding_method='viterbi')\n",
        "print(f\"F1 Score (Viterbi, validation data): {f1_viterbi_val:.4f}\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluating on Validation Data ---\n",
            "Greedy decoding accuracy on validation data: 0.9169\n",
            "\n",
            "Confusion Matrix (Greedy, validation data):\n",
            "[[ 1505    22   261   173    14]\n",
            " [   58   506   339    98     6]\n",
            " [   46    92 40622   379    25]\n",
            " [  263    51   712  1176    48]\n",
            " [   23    19  1231   217  1200]]\n",
            "Confusion Matrix Labels: ['LOC', 'MISC', 'O', 'ORG', 'PER']\n",
            "F1 Score (Greedy, validation data): 0.9096\n",
            "\n",
            "Viterbi decoding accuracy on validation data: 0.9290\n",
            "\n",
            "Confusion Matrix (Viterbi, validation data):\n",
            "[[ 1509    21   217   194    34]\n",
            " [   19   652   239    77    20]\n",
            " [   52   140 40308   485   179]\n",
            " [  145    30   506  1529    40]\n",
            " [   20    12   827   228  1603]]\n",
            "F1 Score (Viterbi, validation data): 0.9269\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}